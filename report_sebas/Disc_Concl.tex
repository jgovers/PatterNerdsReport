\section{Conclusion and Discussion}
\label{sec:DiscConcl}

For Case 1, the recommended classifier is a Parzen density estimating classifier, combined using the product rule with a quadratic discriminant classifier which is applied to a dataset whose dimensionality is reduced using principle component analysis preserving 90\% of the original variance. All provided data was used to train this classifier (10x1000=10,000 objects). The error rate was determined to be 0.0219 with standard deviation 5.3125e-4 using cross validation. The benchmark test yields an error rate of 0.0260.\\
For Case 2, \\



for the support vector classifier, only polynomial kernels were tried. Different kernels might have produced a different (better) result. Especially an advanced kernel like the ‘tangent distance kernel’, which incorporates rotation- and scaling insensitivity, might have improved the error rate.\\
prototypes vastzetten! dus wel  kiezen, en dan je batch daar steeds mee vergelijken.
\\
SVM for pixeldata rep: could have investigated more Kernels?
\\
\noindent For both cases the set criterions were met, but various possibilities for improvement remain. To start with the image preprocessing, the size of the images was chosen to be 16x16 pixels. This choice was motivated by the wish to reduce the runtimes of the algorithms. The effect of using differently resized images for training could be investigated in the future. It seems logical that using larger, more detailed images, could improve classification up to a certain point. Similarly with the value for the Gauss filter: it was chosen to be 0.8 using visual inspection of the resulting images, but this value was not optimized considering the error rates of the classifiers. \\
Besides, when investigating scenario 1, PCA turned out to interfere dramatically with the performance of the Parzen classifier. This effect cannot be explained by the authors and warrants further research. \\
In the interest of time, support vector machines were not considered in this report. According to the literature they offer a promising prospect for classifying in high dimensional spaces, which would be a major advantage especially when using the pixel representation. For scenario 1, a brief look was given dissimilarity measures. Results were promising, but could not be pursued further, because the workings of this method were only presented to us in the very last lecture, leaving no time to investigate them thoroughly in between exams for other subjects. Testing the classifiers for different dissimilarity measures and using meticulously chosen prototypes might have improved the error rates, maybe beyond the results attained using the pixel representation.





\section{Recommendations}
\label{sec:recom}

When continuing designing the digit classification system for the purpose of classifying bank cheques, the following points are worth taking a closer look at. 
\begin{itemize}
	\item \textbf{Implement a reject option:} Especially when dealing with important interactions like bank cheques, any mistake made by the system may be a costly one. It is possible to lower the error rate further by implementing a reject option. This means that the system will abstain from making a definitive decision when the digit cannot be classified with a certainty above a certain threshold. After a digit is rejected several continuations are possible: the cheque containing a rejected digit can then be handled by human employees, or the submitter of the cheque can be contacted automatically, for example.	
	\item \textbf{Discontinue case 2 classification:} In case 2, a new classifier is trained for every batch of cheques to be processed. It seems difficult to come up with a real world scenario in which this would be an efficient procedure. A large training set containing handwritten digits is available, which makes it possible to create a classifier with an error rate below 3\%. This classifier can easily be used for all batches of cheques, without adaptation problems. To keep the classifier up to date with handwriting trends it can be retrained after a certain amount of time. 
	Training a new classifier for every batch delivers an error rate close to 20\%. Practically all submitted cheques would suffer misclassification in several digits. Discontinuation of this procedure should therefore be considered.
	
	\item \textbf{Investigate adding extra features:} The image analysis toolbox used in this report produces at most 14 usable features. This turned out to be insufficient to reach the thresholds set for the error rate. If the dimensionality of the feature space could be enlarged, this might benefit the performance of the classifiers (for case 1 in particular). Investigating ways to extract more features from the given images might turn out to be beneficial. Classifying using feature representation might be able to compete with the pixel data approach.
	\item \textbf{Investigate combining different representations:} The possibility to combine classifiers was considered in this report, but not the combination of different representations. Possibilities for combining classifiers are endless, because not only to classifiers to combine, but also the combining rule can be modified (product, max, min, etc.). Combining a classifier which is able to classify ‘8’ and ‘9’ using features or dissimilarities, with the classifiers described above using the pixel data approach, might further decrease the error rate. 
	\item \textbf{More training data?:} For scenario 2, using more training data would obviously help, but this is not in the spirit of this scenario. For scenario 1 a learning curve was made for the recommended combination of classifiers, which can be seen in figure \ref{fig:learning}. The apparent error sinks to zero, because the Parzen classifier gives an error of zero on its own training set. The estimated true error seems to converge to an asymptotic value. This suggests that the attained error will not decrease significantly after adding more training objects.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{images/pr_figure_5.png}
	\caption{Learning curve for the combined classifier of Case 1.}
	\label{fig:learning}
\end{figure}
	\item \textbf{Remarks about computation time}
	\begin{enumerate}
		\item \textit{Case 1:} For Case 1, once the classifier is trained on the entire dataset, time is not so much an issue. The training of the classifier itself takes a long time though. This is due to the large amount of data, in combination with the relatively cumbersome image processing algorithms in the pre-processing phase. If, for whatever reason, a new classifier has to be trained on a new datafile of numbers, this should be taken into account.
		\item \textit{Case 2:} In the instance of Case 2, more could be done to optimize the training of the classifier. Since the classifier is trained for each batch of cheques (and there will presumably be a lot of batches) this will benefit the user. Again, the most time-consuming factor here is the pre-processing. One way to optimize this (and by the way, this will also work for Case 1!) is to incorporate parallel computing in the algorithm, using \texttt{parfor} in stead of \texttt{for} loops. This will spread the calculations over the different cores of the computer, resulting in a much faster runtime.
	\end{enumerate}
\end{itemize}